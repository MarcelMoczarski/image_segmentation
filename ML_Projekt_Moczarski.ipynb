{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcL_97iBWkWx"
   },
   "source": [
    "#Import Data and and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 192261,
     "status": "ok",
     "timestamp": 1629032651159,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "2BRjOkKvWEIp",
    "outputId": "d412fb4b-7fd5-493f-f00e-50bd1cce736a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount(\"/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1629032651160,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "3HDXNCkqdSEz",
    "outputId": "0b16e1a2-a837-495b-9b42-7df6bc033b60"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1629032740375,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "cNXHDZdN6b0c",
    "outputId": "544be6c1-dc14-43df-d6fe-92d9b8ff88e4"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxGfo4guYiq8"
   },
   "outputs": [],
   "source": [
    "#hier path zum https://www.kaggle.com/aryashah2k/breast-ultrasound-images-dataset Datensatz einf√ºgen(archive.zip)\n",
    "#dieser Datensatz sollte im google drive gespeichert sein, da das einlesen der Bilder andernfalls Ewigkeiten dauert\n",
    "#im Ordner models werden die einzelnen Modelle gespeichert\n",
    "drive_path_history = \"/gdrive/MyDrive/Marcel_Moczarski/Universtiy/Semester/SS_2021/ML/models/\" \n",
    "drive_path = \"/gdrive/MyDrive/Marcel_Moczarski/Universtiy/Semester/SS_2021/ML/Code/archive.zip\"\n",
    "\n",
    "local_path = \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivDhz8D_J05D"
   },
   "outputs": [],
   "source": [
    "#damit die Bilddaten schneller eingelesen werden, wird die archive.zip in die lokale Umgebung kopiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jZr1YEIgFsm"
   },
   "outputs": [],
   "source": [
    "!cp '{drive_path}' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "risL9nEehKpu"
   },
   "outputs": [],
   "source": [
    "os.chdir(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlNX4wf2hRo-"
   },
   "outputs": [],
   "source": [
    "!unzip -q 'archive.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSdEDKtVYk5E"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import glob\n",
    "import cv2 \n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1Jd4PVTV9uq"
   },
   "outputs": [],
   "source": [
    "#Metrik und Loss-Funktion\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "  y_true_f = K.flatten(y_true)\n",
    "  y_pred_f = K.flatten(y_pred)\n",
    "  intersect = K.sum(y_true_f * y_pred_f)\n",
    "  return (intersect + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersect * 1.0)\n",
    "\n",
    "def jaccard_coef_loss(y_true, y_pred):\n",
    "  return -jaccard_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-URmOFmWY_M8"
   },
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJxIN8f8ZWCT"
   },
   "outputs": [],
   "source": [
    "main_path = \"Dataset_BUSI_with_GT/\"\n",
    "sub_path = os.listdir(main_path)\n",
    "\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "img_channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5953,
     "status": "ok",
     "timestamp": 1629035045402,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "_Xk7VVbyZWsz",
    "outputId": "68a1454d-448f-49dc-90f8-78bbea4d2cdf"
   },
   "outputs": [],
   "source": [
    "#Einlesen der Bilder\n",
    "list_img = []\n",
    "list_mask = []\n",
    "label = [0, 1, 2]\n",
    "Y = []\n",
    "for sub, l  in tqdm(zip(sub_path, label), total=len(sub_path)):\n",
    "    items_img = sorted(glob.glob(main_path + sub + \"/*).png\"))\n",
    "    items_mask = sorted(glob.glob(main_path + sub + \"/*_mask*.png\"))\n",
    "    for img in items_img:\n",
    "        tmp_img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "        tmp_img = cv2.resize(tmp_img, (img_height, img_width))\n",
    "        list_img.append(tmp_img)\n",
    "        Y.append(l)\n",
    "    for img in items_mask:\n",
    "        tmp_img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "        tmp_img = cv2.resize(tmp_img, (img_height, img_width))\n",
    "        if(img[-5] != \"k\"):\n",
    "            tmp_img = (list_mask[-1] + tmp_img).clip(0, 255)\n",
    "            list_mask[-1] = tmp_img\n",
    "        else:\n",
    "            list_mask.append(tmp_img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQPBrZk54nXb"
   },
   "outputs": [],
   "source": [
    "#Skalierung der Bilder\n",
    "data_img = np.array(list_img)/255.\n",
    "data_mask = np.array(list_mask)/255.\n",
    "data_Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7Cdoh7qxgAY"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, y_class_train, y_class_test = train_test_split(\n",
    "    data_img, data_mask, data_Y, test_size=0.33, random_state=seed, stratify=data_Y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nnx4KxSNLOYy"
   },
   "outputs": [],
   "source": [
    "def aug_data(X_train, y_train, y_class_train, aug_transforms=[]):\n",
    "  X_train_aug = X_train\n",
    "  y_train_aug = y_train\n",
    "  y_class_train_aug = y_class_train\n",
    "\n",
    "  for transform in aug_transforms:\n",
    "    if transform == \"horizontal_flip\":\n",
    "      X_train_aug = np.concatenate([X_train_aug, np.array([np.flipud(i) for i in X_train])])\n",
    "      y_train_aug = np.concatenate([y_train_aug, np.array([np.flipud(i) for i in y_train])])\n",
    "      y_class_train_aug = np.concatenate([y_class_train_aug, y_class_train])\n",
    "\n",
    "    if transform == \"vertical_flip\":\n",
    "      X_train_aug = np.concatenate([X_train_aug, np.array([np.fliplr(i) for i in X_train])])\n",
    "      y_train_aug = np.concatenate([y_train_aug, np.array([np.fliplr(i) for i in y_train])])\n",
    "      y_class_train_aug = np.concatenate([y_class_train_aug, y_class_train])\n",
    "\n",
    "    if transform == \"right_rotation\":\n",
    "      X_train_aug = np.concatenate([X_train_aug, np.array([np.rot90(i) for i in X_train])])\n",
    "      y_train_aug = np.concatenate([y_train_aug, np.array([np.rot90(i) for i in y_train])])\n",
    "      y_class_train_aug = np.concatenate([y_class_train_aug, y_class_train])\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    rnd_num = rng.integers(0, len(X_train_aug), len(X_train_aug))\n",
    "    X_train_aug = X_train_aug[rnd_num]\n",
    "    y_train_aug = y_train_aug[rnd_num]\n",
    "    y_class_train_aug = y_class_train_aug[rnd_num]\n",
    "\n",
    "  return X_train_aug, y_train_aug, y_class_train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-j5L75JQwRr"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, y_class_train = aug_data(X_train, y_train, y_class_train, [\"horizontal_flip\", \"vertical_flip\"])\n",
    "y_class_train = tf.keras.utils.to_categorical(y_class_train, 3)\n",
    "y_class_test = tf.keras.utils.to_categorical(y_class_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-t_8gWkq0c6Z"
   },
   "outputs": [],
   "source": [
    "#hier manuell die Anzahl der Ebenen und Filter eingeben\n",
    "network_levels = 4\n",
    "network_filters = 32\n",
    "network_params = [network_levels, network_filters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aA4WOgZlXL73"
   },
   "source": [
    "#Constructing the U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9C0lc26iHpd"
   },
   "outputs": [],
   "source": [
    "#Encoder-Path-Block\n",
    "def contract_layer(layer, f, f_size=(3,3), dropout=0.1, nopool=False):\n",
    "    p = 0\n",
    "    c = tf.keras.layers.Conv2D(\n",
    "        f, f_size, activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\"\n",
    "    )(layer)\n",
    "    \n",
    "    c = tf.keras.layers.Dropout(dropout)(c)\n",
    "        \n",
    "    c = tf.keras.layers.Conv2D(\n",
    "        f, f_size, activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\"\n",
    "    )(c)\n",
    "    \n",
    "    if nopool == False: #da die unterste Ebene keine Pooling-Operation erh√§lt\n",
    "        p = tf.keras.layers.MaxPooling2D((2, 2))(c)\n",
    "        \n",
    "    return c, p #gibt den Block vor und nach dem Pooling zur√ºck, der pure Conv2d-Layer wird als Skip-Con. verwendet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CMyaWhmiIZd"
   },
   "outputs": [],
   "source": [
    "#Decoder-Path-Block\n",
    "def expand_layer(\n",
    "    layer, concatlayer, f, fT_size=(2,2), f_size=(3,3), strides=(2,2), dropout=0.1\n",
    "):\n",
    "    up_layer = tf.keras.layers.Conv2DTranspose(\n",
    "        f, fT_size, strides=strides, padding=\"same\"\n",
    "    )(layer)\n",
    "    \n",
    "    up_layer = tf.keras.layers.concatenate([up_layer, concatlayer])\n",
    "    \n",
    "    c = tf.keras.layers.Conv2D(\n",
    "        f, f_size, activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\"\n",
    "    )(up_layer)\n",
    "    \n",
    "    c = tf.keras.layers.Dropout(dropout)(c) \n",
    "    \n",
    "    c = tf.keras.layers.Conv2D(\n",
    "        f, f_size, activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\"\n",
    "    )(c)\n",
    "\n",
    "    c = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=0.9)(c) #from VGG16\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfWqQnVMtTw_"
   },
   "outputs": [],
   "source": [
    "#Erstellung des Unets mit Hilfe obiger Bl√∂cke\n",
    "def buildCNN(h, w, c, levels, filtersize):\n",
    "  layers = []\n",
    "  drop = 0.0\n",
    "  inputs = tf.keras.layers.Input((h, w, c))\n",
    "  in_layer = inputs\n",
    "\n",
    "  for l in range(levels):\n",
    "    if (l % 2) == 0:\n",
    "      drop = drop*10\n",
    "      drop = (drop + 1)/10\n",
    "    c_tmp, p_tmp = contract_layer(in_layer, filtersize, dropout=drop)\n",
    "    in_layer = p_tmp\n",
    "    layers.append([c_tmp, p_tmp])\n",
    "    filtersize = int(2*filtersize)\n",
    "\n",
    "  drop = drop*10\n",
    "  drop = (drop + 1)/10\n",
    "  in_layer, _ = contract_layer(in_layer, filtersize, dropout=drop, nopool=True)\n",
    "  layers.append([in_layer, \"_\"])\n",
    "  drop = drop*10\n",
    "  drop = (drop - 1)/10\n",
    "  filtersize = int(filtersize/2)\n",
    "\n",
    "  for l in range(levels)[::-1]:\n",
    "    c_tmp= expand_layer(layers[-1][0], layers[l][0], filtersize, dropout=drop)\n",
    "    layers.append([c_tmp, \"_\"])\n",
    "    if (l % 2) == 0:\n",
    "      drop = drop*10\n",
    "      drop = (drop - 1)/10\n",
    "    filtersize = int(filtersize/2)\n",
    "\n",
    "  out_layer = tf.keras.layers.Conv2D(1, (1, 1), activation=\"sigmoid\")(layers[-1][0])\n",
    "  \n",
    "  model = tf.keras.Model(inputs=[inputs], outputs=[out_layer])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cE4AjLxPVXCx"
   },
   "outputs": [],
   "source": [
    "model1 = buildCNN(img_height, img_width, img_channel, network_levels, network_filters)\n",
    "model1.compile(optimizer=\"adam\", loss=[jaccard_coef_loss], metrics=[jaccard_coef, \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUsVam9MiOI1"
   },
   "outputs": [],
   "source": [
    "monitor = \"val_loss\"\n",
    "callbacks1 = [\n",
    "             tf.keras.callbacks.EarlyStopping(patience=20, monitor=monitor), \n",
    "             tf.keras.callbacks.ModelCheckpoint(\"best_model_weights.h5\", verbose=1, save_best_only=True, mode=\"min\"),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=10, verbose=1, min_delta=1e-4, mode=\"min\"),\n",
    "             tf.keras.callbacks.TensorBoard(\"logs\", histogram_freq=1), #nur damit w√§hrend des langen Trainings einsicht auf Loss und Metrik m√∂glich ist\n",
    "             ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2669519,
     "status": "ok",
     "timestamp": 1628891327012,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "3IvQtPy6iPCF",
    "outputId": "4d4a017d-97f4-4d13-994d-32753f3d868b"
   },
   "outputs": [],
   "source": [
    "network_history1 = model1.fit(\n",
    "    X_train, y_train, validation_split=0.2, batch_size=16, epochs=epochs, callbacks=callbacks1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAw_ht532Cct"
   },
   "outputs": [],
   "source": [
    "model1.load_weights(filepath=\"best_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI8YDfI5YgVy"
   },
   "source": [
    "#Constructing the Attention-Recurrent-Residual-U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPH_96ftrx8z"
   },
   "outputs": [],
   "source": [
    "#Attention-Block\n",
    "def AttBlock(x, g, filter):\n",
    "  theta = tf.keras.layers.Conv2D(filter, (2 ,2), strides=(2, 2), padding=\"same\")(x)\n",
    "  phi = tf.keras.layers.Conv2D(filter, (1 ,1), strides=(1, 1), padding=\"same\")(g)\n",
    "  phi = tf.keras.layers.Conv2DTranspose(filter, (3, 3), strides=(1, 1), padding=\"same\")(phi)\n",
    "\n",
    "  added_layers = tf.keras.layers.Add()([phi, theta])\n",
    "  added_layers = tf.keras.layers.Activation(\"relu\")(added_layers)\n",
    "\n",
    "  psi = tf.keras.layers.Conv2D(1, (1 ,1), padding=\"same\")(added_layers)\n",
    "  psi = tf.keras.layers.Activation(\"sigmoid\")(psi)\n",
    "\n",
    "  psi = tf.keras.layers.Conv2DTranspose(filter, (3, 3), strides=(2, 2), padding=\"same\")(psi)\n",
    "\n",
    "  up_layer = tf.keras.layers.multiply([psi, x])\n",
    "  up_layer = tf.keras.layers.Conv2D(filter, (1, 1), padding=\"same\")(up_layer)\n",
    "  up_layer = tf.keras.layers.BatchNormalization()(up_layer)\n",
    "\n",
    "  return up_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzdB6IabRycc"
   },
   "outputs": [],
   "source": [
    "#Encoder-Block, diesmal mit Residual- und Rec-Operationen\n",
    "def R2Block(x, filter, kernel=(3,3), dropout=0.1, nopool=False): #filter = filtersize = #features, kernel=kernel_size\n",
    "  skip_connect = tf.keras.layers.Conv2D(filter, 1, padding=\"same\")(x) #skip connection\n",
    "  skip_connect = tf.keras.layers.BatchNormalization()(skip_connect)\n",
    "  x = skip_connect\n",
    "  for i in range(2): #corresponds to c1 and c2 compared to normal unet\n",
    "    c = tf.keras.layers.Conv2D(filter, kernel, padding=\"same\")(x)\n",
    "    c = tf.keras.layers.BatchNormalization()(c)\n",
    "    c = tf.keras.layers.Activation(\"relu\")(c)\n",
    "    for i in range(2): #recurrent loop for each c_2\n",
    "      added_layers = tf.keras.layers.Add()([c, x])\n",
    "      c = tf.keras.layers.Conv2D(filter, kernel, padding=\"same\")(added_layers)\n",
    "      c = tf.keras.layers.BatchNormalization()(c)\n",
    "      c = tf.keras.layers.Activation(\"relu\")(c)\n",
    "    x = c\n",
    "\n",
    "  connected = tf.keras.layers.Add()([skip_connect, x]) #hier Residual\n",
    "  connected = tf.keras.layers.Activation(\"relu\")(connected)\n",
    "  \n",
    "  if nopool == False: \n",
    "      x = tf.keras.layers.MaxPooling2D((2, 2))(connected)\n",
    "      \n",
    "  return connected, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMm4bSJPR1BD"
   },
   "outputs": [],
   "source": [
    "def UpSamplingBlock(x, connection, filter, kernel=(3,3), strides=(2,2), dropout=0.1): #x = down_layer\n",
    "  #gating-signal\n",
    "  gating_signal = tf.keras.layers.Conv2D(filter, (1,1), padding=\"same\")(x) #to get down_layer features to size of up_layer\n",
    "  gating_signal = tf.keras.layers.BatchNormalization()(gating_signal)\n",
    "  gating_signal = tf.keras.layers.Activation(\"relu\")(gating_signal)\n",
    "  \n",
    "  #attention-block\n",
    "  att = AttBlock(connection, gating_signal, filter) #attention block with r2blocks\n",
    "  up_layer = tf.keras.layers.Conv2DTranspose(filter, kernel, strides=strides, activation=\"relu\", padding=\"same\")(x)\n",
    "  concated_up_layer = tf.keras.layers.concatenate([up_layer, att])\n",
    "\n",
    "  #R2-block\n",
    "  concated_conv, _ = R2Block(concated_up_layer, filter)\n",
    "\n",
    "  return concated_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Z4cD6RfkARq"
   },
   "outputs": [],
   "source": [
    "#Erstellt das AR2-U-Net \n",
    "def ResbuildCNN(h, w, c, levels, filtersize):\n",
    "  tf.keras.backend.clear_session()\n",
    "\n",
    "  layers = []  #saves conv blocks for concatenate in extensive path + pooled layers for next lower level in contraction path             \n",
    "  inputs = tf.keras.layers.Input((h, w, c))\n",
    "  in_layer = inputs\n",
    "\n",
    "  for l in range(levels):\n",
    "    c_tmp, p_tmp = R2Block(in_layer, filtersize)\n",
    "    in_layer = p_tmp\n",
    "    layers.append([c_tmp, p_tmp])\n",
    "    filtersize = int(2*filtersize)\n",
    "\n",
    "  in_layer, _ = R2Block(in_layer, filtersize, nopool=True)\n",
    "  layers.append([in_layer, \"_\"])\n",
    "  filtersize = int(filtersize/2)\n",
    "\n",
    "  for l in range(levels)[::-1]:\n",
    "    c_tmp = UpSamplingBlock(layers[-1][0], layers[l][0], filtersize) \n",
    "    layers.append([c_tmp, \"_\"])\n",
    "    filtersize = int(filtersize/2)\n",
    "\n",
    "  out_layer = tf.keras.layers.Conv2D(1, (1, 1), activation=\"sigmoid\")(layers[-1][0])\n",
    "  \n",
    "  model = tf.keras.Model(inputs=[inputs], outputs=[out_layer])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtuiBB98ZHoz"
   },
   "outputs": [],
   "source": [
    "model2 = ResbuildCNN(img_height, img_width, img_channel, network_levels, network_filters)\n",
    "model2.compile(optimizer=\"adam\", loss=[jaccard_coef_loss], metrics=[jaccard_coef, \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJetH_-SSU4L"
   },
   "outputs": [],
   "source": [
    "monitor = \"val_loss\"\n",
    "callbacks2 = [\n",
    "             tf.keras.callbacks.EarlyStopping(patience=20, monitor=monitor), \n",
    "             tf.keras.callbacks.ModelCheckpoint(\"best_model2_weights.h5\", verbose=1, save_best_only=True, monitor=\"val_loss\", mode=\"min\"),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=10, verbose=1, min_delta=1e-4, mode=\"min\"),\n",
    "             tf.keras.callbacks.TensorBoard(\"logs\", histogram_freq=1),\n",
    "             ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dh-tZls369vI"
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lw4iMmlAR4Yz",
    "outputId": "81e86d96-8960-4edf-8bf9-6ea29d0464c3"
   },
   "outputs": [],
   "source": [
    "network_history2 = model2.fit(\n",
    "    X_train, y_train, validation_split=0.2, batch_size=16, epochs=epochs, callbacks=callbacks2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHthhBtAR65D"
   },
   "outputs": [],
   "source": [
    "model2.load_weights(filepath=\"best_model2_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2AEtrEVXqlQ"
   },
   "source": [
    "#Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmkM6IN-R8vc"
   },
   "outputs": [],
   "source": [
    "preds_test1 = model1.predict(X_test, verbose=1)\n",
    "preds_test2 = model2.predict(X_test, verbose=1)\n",
    "\n",
    "preds_test1 = np.squeeze(preds_test1 > 0.5)\n",
    "preds_test2 = np.squeeze(preds_test2 > 0.5)\n",
    "\n",
    "print(\"model1: \", model1.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"model2: \", model2.evaluate(X_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UVU8ZO38Sce"
   },
   "source": [
    "#Save Models and Histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6O_p4lSURhC"
   },
   "outputs": [],
   "source": [
    "#plottet die Loss- und Metrik-Kurven\n",
    "def plot_history(history, save_path, model_name): \n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Jaccard Loss')\n",
    "  plt.plot(history['loss'])\n",
    "  plt.plot(history['val_loss'])\n",
    "  plt.legend(['Training', 'Validation'])\n",
    "  plt.grid(ls=\"dotted\")\n",
    "  plt.savefig(save_path + \"/\" + model_name + \"_att_r2_unet_jaccard_loss.pdf\")\n",
    "  plt.clf()\n",
    "\n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Jaccard coefficient')\n",
    "  plt.plot(history['jaccard_coef'])\n",
    "  plt.plot(history['val_jaccard_coef'])\n",
    "  plt.legend(['Training', 'Validation'])\n",
    "  plt.grid(ls=\"dotted\")\n",
    "  plt.savefig(save_path + \"/\" + model_name + \"_att_r2_unet_jaccard_coef.pdf\")\n",
    "  plt.clf()\n",
    "\n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.plot(history['accuracy'])\n",
    "  plt.plot(history['val_accuracy'])\n",
    "  plt.legend(['Training', 'Validation'])\n",
    "  plt.grid(ls=\"dotted\")\n",
    "  plt.savefig(save_path + \"/\" + model_name + \"_att_r2_unet_accuracy.pdf\")\n",
    "  plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3pC_6zm8WIm"
   },
   "outputs": [],
   "source": [
    "#Speichert die Modelle, sowie die Loss- und Metrik-Kurven, sowie die Maximalen Scores auf dem Testdatensatz\n",
    "def save_history(model1, model2, history1, history2, new_run = True):\n",
    "  save_path = drive_path_history + str(img_height) \n",
    "\n",
    "  if os.path.isdir(save_path) == False:\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "  save_path = drive_path_history + str(img_height) + \"/\" + \"levels_\" + str(network_levels) + \"-\" + \"filters_\" + str(network_filters)\n",
    "  current_run = \"0\" \n",
    "\n",
    "  if os.path.isdir(save_path) == False:\n",
    "    os.mkdir(save_path)\n",
    "  runs = os.listdir(save_path)\n",
    "  if len(runs) == 0:\n",
    "    current_run = \"/01\"\n",
    "    save_path = save_path + current_run\n",
    "    os.mkdir(save_path)\n",
    "  else:\n",
    "    run_int = int(runs[-1])\n",
    "    if new_run == True:\n",
    "      run_int = run_int + 1\n",
    "      if run_int < 10:\n",
    "        current_run = \"/0\" + str(run_int)\n",
    "      else:\n",
    "        current_run = \"/\" + str(run_int)\n",
    "      save_path = save_path + current_run\n",
    "      os.mkdir(save_path)\n",
    "    else:\n",
    "        current_run = \"/\" + runs[-1]\n",
    "        save_path = save_path + current_run\n",
    "  model1.save(save_path + \"/model1_weights.h5\")\n",
    "  model2.save(save_path + \"/model2_weights.h5\")\n",
    "  \n",
    "  pd.DataFrame(history1.history).to_csv(save_path + \"/model1_history.csv\", index=False)\n",
    "  pd.DataFrame(history2.history).to_csv(save_path + \"/model2_history.csv\", index=False)\n",
    "\n",
    "  plot_history(history1.history, save_path, \"model1\")\n",
    "  plot_history(history1.history, save_path, \"model2\")\n",
    "\n",
    "  np.savetxt(save_path + \"/model1_score.txt\", model1.evaluate(X_test, y_test, verbose=0))\n",
    "  np.savetxt(save_path + \"/model2_score.txt\", model2.evaluate(X_test, y_test, verbose=0))\n",
    "\n",
    "save_history(model1, model2, network_history1, network_history2, False) #False damit kein neuer Ordner mit neuem Model erstellt wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFTZbxtF_5sG"
   },
   "outputs": [],
   "source": [
    "#sucht das beste U-Net Modell und das beste AR2-U-Net-Modell, sowie die Scores aller Modelle\n",
    "def get_models():\n",
    "    models = [\"model1\", \"model2\"]\n",
    "    highscore = []\n",
    "    score_comp = []\n",
    "    for model in models:\n",
    "        scores_list = glob.glob(drive_path_history + str(img_height) + \"/**/*\"+ model + \"_score.txt\", recursive=True)\n",
    "        scores = np.zeros(len(scores_list))\n",
    "        score_comp_arr = np.zeros((len(scores), 3))\n",
    "        for i, s in enumerate(scores_list):\n",
    "            scores[i] = np.genfromtxt(s)[1]\n",
    "            \n",
    "            start = s.find(\"levels_\") + len(\"levels_\")\n",
    "            end = s.find(\"-filter\")\n",
    "            l = s[start:end]\n",
    "            start = s.find(\"filters_\") + len(\"filters_\")\n",
    "            end = -20\n",
    "            f = s[start:end]\n",
    "            \n",
    "            score_comp_arr[i, 0] = l\n",
    "            score_comp_arr[i, 1] = f\n",
    "            score_comp_arr[i, 2] = scores[i]\n",
    "        score_comp.append(score_comp_arr)\n",
    "        best_model_path = scores_list[scores.argmax()][:-9] + \"weights.h5\"\n",
    "        highscore.append(best_model_path)\n",
    "    return highscore, score_comp\n",
    "highscore, scores = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1629039045035,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "Iym76wV7Sp5j",
    "outputId": "5fab9c20-ef40-4329-b75d-661e0a234bea"
   },
   "outputs": [],
   "source": [
    "#Zur √úberpr√ºfung, welches das beste Model ist\n",
    "highscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7575,
     "status": "ok",
     "timestamp": 1629054287732,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "XgHcXzrhAdXN",
    "outputId": "93485106-a6b2-4a56-da8f-1696dd7fbcd8"
   },
   "outputs": [],
   "source": [
    "#l√§dt die besten Modelle, und erstellt die Vorhersagen\n",
    "best_model1 = tf.keras.models.load_model(filepath=highscore[0], compile=False)\n",
    "best_model2 = tf.keras.models.load_model(filepath=highscore[1], compile=False)\n",
    "\n",
    "best_model1.compile(optimizer=\"adam\", loss=[jaccard_coef_loss], metrics=[jaccard_coef, \"accuracy\"])\n",
    "best_model2.compile(optimizer=\"adam\", loss=[jaccard_coef_loss], metrics=[jaccard_coef, \"accuracy\"])\n",
    "\n",
    "preds_test1 = best_model1.predict(X_test, verbose=1)\n",
    "preds_test2 = best_model2.predict(X_test, verbose=1)\n",
    "\n",
    "preds_test1 = np.squeeze(preds_test1 > 0.5)\n",
    "preds_test2 = np.squeeze(preds_test2 > 0.5)\n",
    "\n",
    "print(\"model1: \", best_model1.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"model2: \", best_model2.evaluate(X_test, y_test, verbose=0))\n",
    "\n",
    "print(highscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1629046799650,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "PaI4LJFJwUn7",
    "outputId": "95d6663d-b0cc-46e7-b115-5c512363a92f"
   },
   "outputs": [],
   "source": [
    "best_model1.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1549,
     "status": "ok",
     "timestamp": 1629046810125,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "jNwy5_u2wYY5",
    "outputId": "fd7ead07-2395-439e-d161-bb17b5a67285"
   },
   "outputs": [],
   "source": [
    "best_model2.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "executionInfo": {
     "elapsed": 1395,
     "status": "ok",
     "timestamp": 1629039675214,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "Fmp9VYlW5z-2",
    "outputId": "ee80cddb-90a2-4ec1-c271-8af6e1846f8f"
   },
   "outputs": [],
   "source": [
    "#Vergleichsplot aller Modelle\n",
    "def plot_comparison(scores, save_path):\n",
    "  scores_sorted_list = []\n",
    "\n",
    "  fig = plt.figure(figsize=(10, 8))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  plot_length = np.bincount(scores[0][:, 0].astype(\"int64\"))\n",
    "\n",
    "  for s in scores:\n",
    "    k = 0\n",
    "    score_counter = np.bincount(s[:,0].astype(\"int64\"))\n",
    "    plot_length = score_counter.sum()\n",
    "    for i in score_counter:\n",
    "      if i != 0:\n",
    "        score_mask = s[:, 0] == k\n",
    "        score_sorted = np.argsort(s[score_mask][:, 1])\n",
    "        tmp_array = s[score_mask][score_sorted]\n",
    "        scores_sorted_list.append(tmp_array)\n",
    "      k = k + 1\n",
    "  scores_sorted_arr = np.concatenate(scores_sorted_list, axis=0 )\n",
    "  x = np.arange(0, plot_length)\n",
    "  x_label = scores_sorted_arr[:plot_length, 1].astype(\"int\")\n",
    "\n",
    "  plt.xticks(x, x_label)\n",
    "  ax.plot(x, scores_sorted_arr[:plot_length, 2], \"o\", label=\"U-Net\")\n",
    "  ax.plot(x, scores_sorted_arr[plot_length:, 2], \"ro\", label=\"AR2-U-Net\")\n",
    "\n",
    "  minimum = scores_sorted_arr[:, 2].min()\n",
    "  maximum = scores_sorted_arr[:, 2].max()\n",
    "  height = maximum - minimum\n",
    "\n",
    "  box_count = np.unique(scores_sorted_arr[:, 0])\n",
    "  colors = cm.Reds(np.linspace(0.3, 0.9, len(box_count)))\n",
    "\n",
    "  count = 0\n",
    "\n",
    "  i_1 = scores_sorted_arr[:plot_length][0, 1]\n",
    "  m = 0\n",
    "  m_list = []\n",
    "  for i in scores_sorted_arr[:plot_length][1:, 1]:\n",
    "    if i < i_1:\n",
    "      i_1 = i\n",
    "      m_list.append(m)\n",
    "    i_1 = i\n",
    "    m = m + 1\n",
    "  m_list = np.asarray(m_list)   \n",
    "  start = 0\n",
    "  tmp_i = 0\n",
    "\n",
    "  for i, (j, c) in enumerate(zip(box_count, colors)):\n",
    "    if i < len(m_list):\n",
    "      end = m_list[i]\n",
    "\n",
    "      tmp = x[start:end]\n",
    "      width = len(tmp) + 0.2\n",
    "      rect = patches.Rectangle((start-0.1, minimum-0.05), width, height+height/2, linewidth=1, edgecolor=c, facecolor=c, alpha=0.3)\n",
    "      ax.add_patch(rect)\n",
    "      start = end+1\n",
    "      textpos = tmp[0] +((tmp[-1]+1 - tmp[0])/2)\n",
    "      plt.text(textpos-0.25, minimum-0.005, \"n = \" + str(int(j)))\n",
    "    else:\n",
    "      end = x[-1]\n",
    "      tmp = x[start:end]\n",
    "      \n",
    "      width = len(tmp) + 0.2\n",
    "#         if width == 0.2:\n",
    "#             width = \n",
    "      rect = patches.Rectangle((start-0.1, minimum-0.05), width, height+height/2, linewidth=1, edgecolor=c, facecolor=c, alpha=0.3)\n",
    "      ax.add_patch(rect)\n",
    "      if len(tmp) > 1:\n",
    "        textpos = tmp[0] +((tmp[-1]+1 - tmp[0])/2)\n",
    "      else: \n",
    "        textpos = x[-1]\n",
    "\n",
    "      plt.text(textpos-0.25, minimum-0.005, \"n = \" + str(int(j)))\n",
    "\n",
    "  ax.set_ylim([minimum - 0.05, maximum + 0.05])\n",
    "  ax.legend()\n",
    "  ax.grid(ls=\"dotted\")\n",
    "  ax.set_xlabel(\"$l(n)$\")\n",
    "  ax.set_ylabel(\"$J$\")\n",
    "  plt.savefig(save_path + \"/\" + str(img_height) + \"/model_comparison.pdf\")\n",
    "plot_comparison(scores, drive_path_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1018,
     "status": "ok",
     "timestamp": 1629054296739,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "qYxhvwn9isAP"
   },
   "outputs": [],
   "source": [
    "#Berechnung der einzelnen Jaccard-Koeffizienten (F√ºr Plot-Legende)\n",
    "coefs1 = np.zeros(len(y_test))\n",
    "coefs2 = np.zeros(len(y_test))\n",
    "\n",
    "for n, (i, j) in enumerate(zip(y_test, np.float64(preds_test1))):\n",
    "  c = jaccard_coef(i, j)\n",
    "  if c > 1:\n",
    "    c = 1\n",
    "  coefs1[n] = c\n",
    "\n",
    "for n, (i, j) in enumerate(zip(y_test, np.float64(preds_test2))):\n",
    "  c = jaccard_coef(i, j)\n",
    "  if c > 1:\n",
    "    c = 1\n",
    "  coefs2[n] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "executionInfo": {
     "elapsed": 3170,
     "status": "ok",
     "timestamp": 1629043820470,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "TAGeZko2k1pm",
    "outputId": "4cc517bb-dfe3-4eaf-c4a5-b6b442ce7c34"
   },
   "outputs": [],
   "source": [
    "# Plottet Beispiel Bilder, inkl. Groundtruth + Prediction beider Modelle\n",
    "def print_img(a):\n",
    "  fig, axs = plt.subplots(2, 4, figsize=(15, 10))\n",
    "  axs[0, 0].imshow(X_test[a], cmap='gray')\n",
    "  axs[0, 1].imshow(y_test[a], cmap='gray')\n",
    "  \n",
    "  axs[0, 2].imshow(preds_test1[a], cmap='gray')\n",
    "  axs[0, 2].plot(0, 0, \"k.\", label=coefs1[a])\n",
    "  axs[0, 2].legend()\n",
    "\n",
    "  axs[0, 3].imshow(preds_test2[a], cmap='gray')\n",
    "  axs[0, 3].plot(0, 0, \"k.\", label=coefs2[a])\n",
    "  axs[0, 3].legend()\n",
    "  \n",
    "  a = a + 3\n",
    "  axs[1, 0].imshow(X_test[a], cmap='gray')\n",
    "  axs[1, 1].imshow(y_test[a], cmap='gray')\n",
    "  \n",
    "  axs[1, 2].imshow(preds_test1[a], cmap='gray')\n",
    "  axs[1, 2].plot(0, 0, \"k.\", label=coefs1[a])\n",
    "  axs[1, 2].legend()\n",
    "\n",
    "  axs[1, 3].imshow(preds_test2[a], cmap='gray')\n",
    "  axs[1, 3].plot(0, 0, \"k.\", label=coefs2[a])\n",
    "  axs[1, 3].legend()\n",
    "\n",
    "  plt.savefig(drive_path_history + \"/\" + str(img_height) +  \"/\" + str(a) + \"_comp.pdf\")\n",
    "rng_img = np.random.default_rng(seed=seed)\n",
    "rnd_num = rng_img.integers(0, len(X_test), 1)\n",
    "print_img(rnd_num[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4NTj8goYLeJ"
   },
   "source": [
    "#A  small comparison to classical Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1664,
     "status": "ok",
     "timestamp": 1629054302134,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "WzupVaZkxRsg"
   },
   "outputs": [],
   "source": [
    "#Canny Edge Detection\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import feature\n",
    "blurred_img = [ndi.gaussian_filter(X_test[i], 4) for i in range(0,len(X_test))]\n",
    "data_canny_edge = [feature.canny(blurred_img[i], sigma=3) for i in range(0,len(X_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1629054304962,
     "user": {
      "displayName": "El Hanzo",
      "photoUrl": "",
      "userId": "07859307094489036524"
     },
     "user_tz": -120
    },
    "id": "1NnV5iCJn8uh",
    "outputId": "0624e64b-7ceb-457a-f439-aad4575bbaaa"
   },
   "outputs": [],
   "source": [
    "a = 30\n",
    "plt.figure(figsize=(13, 3))\n",
    "plt.subplot(141)\n",
    "plt.imshow(X_test[a], cmap='gray')\n",
    "plt.subplot(142)\n",
    "plt.imshow(y_test[a], cmap='gray')\n",
    "plt.subplot(143)\n",
    "plt.imshow(preds_test1[a], cmap='gray')\n",
    "plt.subplot(144)\n",
    "plt.imshow(data_canny_edge[a], cmap='gray')\n",
    "plt.savefig(drive_path_history + \"/\" + str(img_height) + \"/canny_edge.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML_project.ipynb",
   "provenance": [
    {
     "file_id": "1FfwXjAr1tw5vfdmT4rNVhj1mVsFUKBal",
     "timestamp": 1628699398454
    },
    {
     "file_id": "1PafwsJRwBYrSjifWMECMPaOuJC68mMec",
     "timestamp": 1628272617417
    },
    {
     "file_id": "1WyAfNrzhenrkzerSPvWS1yj7hJaj5IfW",
     "timestamp": 1626877995123
    },
    {
     "file_id": "1R5-vxtOMYWqQPhLdo7CuSVhevZI2kUhL",
     "timestamp": 1626707947938
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
